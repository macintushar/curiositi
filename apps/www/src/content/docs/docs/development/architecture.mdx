---
title: ðŸ§± Architecture
description: System architecture and technical overview of Curiositi
---

Curiositi is a monorepo built with Turborepo and Bun. This document explains the system architecture, data flow, and technical decisions.

## High-Level Architecture

```mermaid
flowchart TB
    subgraph Client["Client Layer"]
        Browser["Browser<br/>(React 19)"]
    end

    subgraph App["Application Layer"]
        Platform["Platform<br/>(TanStack Start)"]
        Worker["Worker<br/>(Hono on Bun)"]
        
        Platform -->|"QStash / bunqueue"| Worker
    end

    subgraph Data["Data Layer"]
        Postgres["PostgreSQL<br/>(Drizzle ORM)"]
        S3["S3 Storage<br/>(Files)"]
    end

    Browser --"HTTPS"--> Platform
    Platform --> Postgres
    Platform --> S3
    Worker --> S3
    Worker --> Postgres
```

## Component Overview

### Platform (Web Application)

**Technology Stack:**
- **Framework:** React 19 + TanStack Start
- **Routing:** TanStack Router (file-based)
- **Data Fetching:** TanStack Query + tRPC v11
- **API:** tRPC for type-safe client-server communication
- **Styling:** Tailwind CSS v4 + shadcn/ui
- **Build Tool:** Vite 7 with Nitro for SSR
- **Auth:** Better Auth (Google OAuth + email/password)
- **Monitoring:** Sentry

**Key Directories:**
```
apps/platform/src/
â”œâ”€â”€ routes/           # TanStack Router route definitions
â”œâ”€â”€ components/       # React components
â”‚   â””â”€â”€ ui/          # shadcn/ui components
â”œâ”€â”€ pages/           # Page-level views
â”œâ”€â”€ layouts/         # Layout components
â”œâ”€â”€ integrations/    # tRPC client and server setup
â”œâ”€â”€ hooks/           # React hooks
â”œâ”€â”€ lib/             # Utilities (auth, upload, etc.)
â”œâ”€â”€ middleware/      # Server middleware
â””â”€â”€ env.ts           # Environment variable validation
```

### Worker (File Processing)

The worker is a Hono server running on Bun that processes uploaded files. It exposes the following endpoints:

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Root health check |
| `/health` | GET | Health status endpoint |
| `/process-file` | POST | File processing endpoint (invoked by QStash/bunqueue) |

The `POST /process-file` endpoint is invoked by the platform via Upstash QStash or bunqueue (for local development).

**Technology Stack:**
- **Framework:** Hono
- **Runtime:** Bun (port 3040)
- **AI:** Vercel AI SDK (`ai` package) with OpenAI and Google providers
- **Queue:** Upstash QStash (production) or bunqueue (local development)

**Key Directories:**
```
apps/worker/src/
â”œâ”€â”€ processors/      # File type processors
â”‚   â”œâ”€â”€ doc.ts      # Document processor (PDF, text, etc.)
â”‚   â”œâ”€â”€ image.ts    # Image processor (JPEG, PNG, etc.)
â”‚   â””â”€â”€ types.ts    # Processor type definitions
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ chunk.ts    # Text chunking (800 tokens, 100 overlap)
â”‚   â””â”€â”€ md.ts       # Markdown utilities
â”œâ”€â”€ process-file.ts # Main file processing logic
â”œâ”€â”€ index.ts        # Hono server entry point
â””â”€â”€ env.ts          # Environment variable validation
```

### Database (PostgreSQL + pgvector)

**Technology Stack:**
- **Database:** PostgreSQL 14+ with pgvector extension
- **ORM:** Drizzle ORM
- **Migrations:** Drizzle Kit

**Key Tables:**
```
Better Auth Tables:
â”œâ”€â”€ user
â”œâ”€â”€ session
â”œâ”€â”€ account
â”œâ”€â”€ organization
â”œâ”€â”€ member
â””â”€â”€ verification

Curiositi Tables:
â”œâ”€â”€ spaces           # Hierarchical spaces (parentSpaceId for nesting)
â”œâ”€â”€ files            # File metadata (name, type, size, S3 key, status)
â”œâ”€â”€ fileContents     # Extracted content chunks + vector embeddings (1536d)
â””â”€â”€ filesInSpace     # Many-to-many junction table
```

### Shared Packages

```
packages/
â”œâ”€â”€ db/              # Database schema and Drizzle config
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ schema.ts   # All table definitions
â”‚       â”œâ”€â”€ client.ts   # Database client
â”‚       â””â”€â”€ index.ts    # Exports
â”œâ”€â”€ share/           # Shared utilities
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ ai/         # AI model definitions (OpenAI, Google)
â”‚       â”œâ”€â”€ constants/  # MIME types, file size limits, allowed types
â”‚       â”œâ”€â”€ fs/         # File system helpers
â”‚       â”œâ”€â”€ logger/     # Structured logging utility
â”‚       â”œâ”€â”€ schemas/    # Shared Zod schemas
â”‚       â””â”€â”€ types/      # Shared type definitions
â”œâ”€â”€ api-handlers/    # Shared API handler logic
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ upload.ts   # File upload handling
â”‚       â”œâ”€â”€ file.ts     # File operations
â”‚       â”œâ”€â”€ space.ts    # Space operations
â”‚       â”œâ”€â”€ queue.ts    # Queue job dispatching
â”‚       â””â”€â”€ response.ts # Response helpers
â”œâ”€â”€ queue/           # Job queue wrapper (supports QStash and bunqueue)
â””â”€â”€ tsconfig/        # Shared TypeScript configurations
```

## Data Flow

### File Upload Flow

```mermaid
flowchart LR
    subgraph Upload["1. User Upload"]
        Browser["Browser"] -->|"tRPC / api/upload"| Platform
        Platform -->|"File"| S3["S3 Storage"]
    end

    subgraph Store["2. Metadata Storage"]
        S3 -->|"File saved"| Platform
        Platform -->|"Save metadata"| DB[(PostgreSQL)]
        DB -->|"Status: pending"| Platform
        Platform -->|"Dispatch job"| Queue["QStash / bunqueue"]
    end

    subgraph Process["3. Background Processing"]
        Queue -->|"Invoke"| Worker["Worker"]
        Worker -->|"Download"| S3
        S3 -->|"File content"| Worker
        Worker -->|"Extract content"| Worker
        Worker -->|"Chunk text"| Worker
        Worker -->|"Generate embeddings"| Worker
        Worker -->|"Store"| DB
        Worker -->|"Status: completed"| DB
    end

    subgraph Ready["4. Search Ready"]
        DB -.->|"File searchable"| Search["Vector Search"]
    end
```

### Search Flow

```mermaid
flowchart TB
    subgraph Step1["1. Query Received"]
        User["User enters query"] --> Platform
    end

    subgraph Step2["2. Embedding Generation"]
        Platform -->|"Query text"| AI["Embedding Model"]
        AI -->|"Query vector"| Platform
    end

    subgraph Step3["3. Vector Search"]
        Platform -->|"Vector"| DB[(pgvector)]
        DB -->|"Top matching chunks"| Platform
    end

    subgraph Step4["4. Result Aggregation"]
        Platform -->|"Group by file"| Results["Results to user"]
    end
```

### Authentication Flow

```mermaid
flowchart TB
    Login["1. Login Request<br/>(Email/Password or Google)"] --> Validate["Better Auth validates"]
    Validate --> Session["2. Session Created<br/>(PostgreSQL + Cookie)"]
    Session --> Workspace["3. Workspace Context<br/>(Select workspace)"]
    Workspace --> Authz["4. Authorization<br/>(Check membership)"]
```

## Technical Decisions

### Why Turborepo?

- **Code Sharing** â€” Shared packages (db, share, api-handlers, queue) reduce duplication
- **Build Optimization** â€” Turborepo caches and parallelizes builds
- **Unified Tooling** â€” Single lint (Biome), format, and type-check across the repo
- **Dependency Management** â€” Workspace protocol for internal dependencies

### Why TanStack Start?

- **File-based Routing** â€” Automatic route generation via TanStack Router
- **Type Safety** â€” End-to-end TypeScript with tRPC integration
- **SSR Support** â€” Built-in server-side rendering via Vite + Nitro
- **Developer Experience** â€” Hot reload and excellent dev tools

### Why Hono for Worker?

- **Performance** â€” Lightweight and fast, runs natively on Bun
- **Simplicity** â€” Single endpoint, minimal framework overhead
- **TypeScript Native** â€” Full type safety out of the box

### Why Drizzle ORM?

- **Type Safety** â€” Full TypeScript support with inferred types
- **SQL-like Syntax** â€” Familiar query building, close to raw SQL
- **Migration Support** â€” Drizzle Kit for schema generation and migrations
- **Performance** â€” Minimal overhead compared to heavier ORMs

### Why pgvector?

- **Native Integration** â€” Vector storage directly in PostgreSQL
- **Similarity Search** â€” Efficient nearest neighbor queries
- **No Additional Services** â€” No need for a separate vector database
- **ACID Compliance** â€” Transactional safety for embeddings alongside relational data

## Monitoring and Observability

### Logging

- **Structured Logging** â€” Custom logger in `packages/share/src/logger/`
- **Log Levels** â€” Debug, Info, Warn, Error

### Error Tracking

- **Sentry** â€” Integrated into the platform for error tracking and performance monitoring

## CI/CD

### GitHub Actions Workflows

```mermaid
flowchart TB
    subgraph ci["ci.yml (push/PR to main)"]
        Format["Format check<br/>(Biome)"]
        Lint["Lint + Type Check<br/>(bun run check)"]
        Commit["Commit message<br/>(commitlint)"]
    end

    subgraph test["test.yml (push/PR to main)"]
        Test["Run tests<br/>(bun run test:coverage)"]
        Codecov["Upload coverage<br/>(Codecov)"]
    end

    subgraph release["release.yml (weekly, Friday 00:00 UTC)"]
        Changeset["Generate changesets"]
        Version["Version packages"]
        GitHub["Create releases/tags"]
    end
```

### Deployment

- **Platform** â€” Deploys to Vercel (TanStack Start + Nitro)
- **Documentation (www)** â€” Deploys to Vercel (Starlight + Astro)
- **Worker** â€” Runs on Bun

## Development

### Local Development

```bash
# Start all services
bun run dev

# Services available:
# - Platform: http://localhost:3030
# - Worker:   http://localhost:3040
```

### Testing

The project uses Bun's built-in test runner and Playwright for E2E tests:

```bash
# Run tests with coverage
bun run test

# Run with lcov coverage output
bun run test:coverage
```

## Next Steps

- [Configuration](/docs/development/configuration) â€” Environment variables and settings
- [Core Concepts](/docs/getting-started/core-concepts) â€” Understand the data model
- [Getting Started](/docs/getting-started/getting-started) â€” Run Curiositi locally
